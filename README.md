# Backchannel_detection:

Backchanneling during a conversation occurs when
one participant is speaking and another participant
gives a response to the speaker. It can be verbal
cues (“uh-huh”, “hmm”), visual cues(“nodding”,
“facial expressions”) or both, these cues are input
modalities used for backchannel detection. The
backchannel has the important function of encour-
aging current speaker to hold their turn and con-
tinue to speak, which enables smooth conversa-
tion. Predicting a backchannel can be beneficial
for building human like conversational agents or
robots

Refer to the report for full understanding of our experiment : https://drive.google.com/file/d/1XLZRns5FUpb33731iPfz5u1UrFK_jzQ2/view?usp=sharing

The above python notebook has the code for the "Backchannel detection". 
To run the python notebook we need '.npy' numpy files which are nothing but explicitly extracted input features of the video dataset(more info on dataset in the report).
The '.npy' files are available here : https://drive.google.com/file/d/1XLZRns5FUpb33731iPfz5u1UrFK_jzQ2/view?usp=sharing.
After downloading these files the location of the files must be changed in the python notebook accordingly.

The following npy files are the only files needs to be downloaded from the above link:

features_face_674_90.npy ,labels_face_674_90.npy ,features_pose_76_90.npy ,labels_pose_76_90.npy, features_test_face_674_90.npy ,labels_test_face_674_90.npy, features_test_pose_76_90.npy ,labels_test_pose_76_90.npy
